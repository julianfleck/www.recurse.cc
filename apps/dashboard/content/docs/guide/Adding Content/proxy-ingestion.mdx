---
title: Via Proxy
description: Add content to Recurse automatically by enabling persistence on the OpenAI‑compatible proxy
---

Use the Recurse proxy not only to retrieve context, but also to add new content automatically. When you enable persistence, Recurse can store the assistant’s final message back into your knowledge graph—scoped to the audience you choose.

<Callout title="When to use" type="warn">You already route model calls through `https://api.recurse.cc/proxy/[provider_url]` and want useful outputs (answers, summaries, notes) to become part of your knowledge over time</Callout>

---

## How it works

- You send a normal Chat Completions request via the proxy
- Recurse retrieves relevant context based on your `scope`
- The provider returns a response
- If `persist` is enabled, Recurse saves the assistant’s final message into your graph under the same `scope`

---

## Enable persistence

You can enable persistence via header or request body. The header takes precedence if both are present.

<Tabs items={['JavaScript', 'Python', 'cURL']} defaultIndex={0}>
  <Tab value="JavaScript">
    ```javascript
    import OpenAI from 'openai';

    const client = new OpenAI({
      apiKey: process.env.OPENAI_API_KEY,
      baseURL: 'https://api.recurse.cc/proxy/https://api.openai.com/v1/',
      defaultHeaders: {
        'X-API-Key': process.env.RECURSE_API_KEY,
        'X-Recurse-Scope': 'meeting_notes',
        'X-Recurse-Persist': 'true'
      }
    });

    const completion = await client.chat.completions.create({
      model: 'gpt-4o-mini',
      messages: [{ role: 'user', content: 'Summarize our weekly meeting decisions.' }]
      // persist: true, // Optional body flag
    });
    ```
  </Tab>

  <Tab value="Python">
    ```python
    from openai import OpenAI
    import os

    client = OpenAI(
        api_key=os.getenv('OPENAI_API_KEY'),
        base_url='https://api.recurse.cc/proxy/https://api.openai.com/v1/',
        default_headers={
            'X-API-Key': os.getenv('RECURSE_API_KEY'),
            'X-Recurse-Scope': 'meeting_notes',
            'X-Recurse-Persist': 'true',
        },
    )

    resp = client.chat.completions.create(
        model='gpt-4o-mini',
        messages=[{'role': 'user', 'content': 'Summarize our weekly meeting decisions.'}],
        # persist=True,  # Optional body flag
    )
    ```
  </Tab>

  <Tab value="cURL">
    ```bash
    curl -X POST "https://api.recurse.cc/proxy/https://api.openai.com/v1/chat/completions" \
      -H "Authorization: Bearer $OPENAI_API_KEY" \
      -H "X-API-Key: $RECURSE_API_KEY" \
      -H "X-Recurse-Scope: meeting_notes" \
      -H "X-Recurse-Persist: true" \
      -H "Content-Type: application/json" \
      -d '{
        "model": "gpt-4o-mini",
        "messages": [{"role": "user", "content": "Summarize our weekly meeting decisions."}]
      }'
    ```
  </Tab>
</Tabs>

> Note: Persisting generated answers consumes storage allowance more quickly. Use thoughtfully.

---

## Organize with scopes

Pick a `scope` that matches how you want to file content—per user, per team, or per collection like `meeting_notes` or `support_faqs`. The same `scope` used for retrieval is also used for storage when persistence is enabled.

---

## Troubleshooting

- No content saved: Ensure `X-Recurse-Persist: true` or `persist: true` is set, and that responses contain an assistant message.
- Wrong place: Verify your `X-Recurse-Scope` matches your intended collection.
- Storage usage: Expect higher storage consumption when persisting frequently.


